#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLM ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ LLM æä¾›å•†ï¼Œæ”¯æŒè‡ªåŠ¨åˆ‡æ¢å’Œè´Ÿè½½å‡è¡¡
"""

from typing import Dict, Optional, List, Any
from enum import Enum

from .base_LLM_provider import (
    BaseLLMProvider,
    LLMRequest,
    LLMResponse,
    ProviderError,
)
from .providers.qwen import QwenProvider
from .providers.kimi import KimiProvider
from .providers.glm5 import GLM5Provider
from .providers.claude import ClaudeProvider
from .providers.gemini import GeminiProvider
from .providers.local import LocalProvider
from .providers.deepseek import DeepSeekProvider


def _safe_import():
    """å®‰å…¨å¯¼å…¥ä¾èµ–"""
    try:
        import httpx
        return httpx
    except ImportError:
        return None


class ProviderType(Enum):
    """æä¾›å•†ç±»å‹"""
    QWEN = "qwen"
    KIMI = "kimi"
    GLM5 = "glm5"
    CLAUDE = "claude"
    GEMINI = "gemini"
    OPENAI = "openai"
    LOCAL = "local"
    DEEPSEEK = "deepseek"


class LLMManager:
    """
    LLM ç®¡ç†å™¨

    åŠŸèƒ½:
    1. ç»Ÿä¸€æ¥å£è®¿é—®æ‰€æœ‰æä¾›å•†
    2. è‡ªåŠ¨åˆ‡æ¢å¤±è´¥æä¾›å•†
    3. é…ç½®é©±åŠ¨
    """

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–ç®¡ç†å™¨

        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.providers: Dict[ProviderType, BaseLLMProvider] = {}
        self._default_provider: Optional[ProviderType] = None

        # åˆå§‹åŒ–æä¾›å•†
        self._init_providers()

    def _init_providers(self):
        """åˆå§‹åŒ–æ‰€æœ‰æä¾›å•†"""
        llm_config = self.config.get("LLM", {})

        # é€šä¹‰åƒé—®
        qwen_config = llm_config.get("qwen", {})
        if qwen_config.get("enabled", False):
            api_key = qwen_config.get("api_key", "")
            if api_key and api_key != "${QWEN_API_KEY}":
                self.providers[ProviderType.QWEN] = QwenProvider(
                    api_key=api_key,
                    base_url=qwen_config.get("base_url", ""),
                )

        # Kimi
        kimi_config = llm_config.get("kimi", {})
        if kimi_config.get("enabled", False):
            api_key = kimi_config.get("api_key", "")
            if api_key and api_key != "${KIMI_API_KEY}":
                self.providers[ProviderType.KIMI] = KimiProvider(
                    api_key=api_key,
                    base_url=kimi_config.get("base_url", ""),
                )

        # GLM-5
        glm5_config = llm_config.get("glm5", {})
        if glm5_config.get("enabled", False):
            api_key = glm5_config.get("api_key", "")
            if api_key and api_key != "${GLM5_API_KEY}":
                self.providers[ProviderType.GLM5] = GLM5Provider(
                    api_key=api_key,
                    base_url=glm5_config.get("base_url", ""),
                )

        # Claude
        claude_config = llm_config.get("claude", {})
        if claude_config.get("enabled", False):
            api_key = claude_config.get("api_key", "")
            if api_key and api_key != "${CLAUDE_API_KEY}":
                self.providers[ProviderType.CLAUDE] = ClaudeProvider(
                    api_key=api_key,
                    base_url=claude_config.get("base_url", "https://api.anthropic.com"),
                )

        # Gemini
        gemini_config = llm_config.get("gemini", {})
        if gemini_config.get("enabled", False):
            api_key = gemini_config.get("api_key", "")
            if api_key and api_key != "${GEMINI_API_KEY}":
                self.providers[ProviderType.GEMINI] = GeminiProvider(
                    api_key=api_key,
                    base_url=gemini_config.get("base_url", "https://generativelanguage.googleapis.com"),
                )

        # æœ¬åœ°æ¨¡å‹
        local_config = llm_config.get("local", {})
        if local_config.get("enabled", False):
            self.providers[ProviderType.LOCAL] = LocalProvider(
                api_key=local_config.get("api_key", ""),
                base_url=local_config.get("base_url", "http://localhost:11434"),
                backend=local_config.get("backend", "ollama"),
            )

        # DeepSeek
        deepseek_config = llm_config.get("deepseek", {})
        if deepseek_config.get("enabled", False):
            api_key = deepseek_config.get("api_key", "")
            if api_key and api_key != "${DEEPSEEK_API_KEY}":
                self.providers[ProviderType.DEEPSEEK] = DeepSeekProvider(
                    api_key=api_key,
                    base_url=deepseek_config.get("base_url", "https://api.deepseek.com"),
                )

        # è®¾ç½®é»˜è®¤æä¾›å•†
        default_name = llm_config.get("default_provider", "qwen")
        try:
            self._default_provider = ProviderType(default_name)
        except ValueError:
            if self.providers:
                self._default_provider = list(self.providers.keys())[0]
            else:
                self._default_provider = None

    async def generate(
        self,
        request: LLMRequest,
        provider: Optional[ProviderType] = None,
    ) -> LLMResponse:
        """
        ç”Ÿæˆæ–‡æœ¬

        Args:
            request: LLM è¯·æ±‚
            provider: æŒ‡å®šæä¾›å•†ï¼ˆå¯é€‰ï¼‰

        Returns:
            LLM å“åº”
        """
        # ç¡®å®šä½¿ç”¨çš„æä¾›å•†
        if provider and provider in self.providers:
            active_provider = self.providers[provider]
        else:
            provider = self._default_provider
            if not provider or provider not in self.providers:
                raise ProviderError("æ²¡æœ‰å¯ç”¨çš„æä¾›å•†")
            active_provider = self.providers[provider]

        try:
            return await active_provider.generate(request)

        except ProviderError as e:
            # è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„æä¾›å•†
            print(f"âš ï¸  æä¾›å•† {provider.value} å¤±è´¥: {e}")
            return await self._try_fallback(request, exclude=[provider])

    async def _try_fallback(
        self,
        request: LLMRequest,
        exclude: List[ProviderType],
    ) -> LLMResponse:
        """
        å°è¯•å¤‡ç”¨æä¾›å•†

        Args:
            request: LLM è¯·æ±‚
            exclude: è¦æ’é™¤çš„æä¾›å•†åˆ—è¡¨

        Returns:
            LLM å“åº”

        Raises:
            ProviderError: æ‰€æœ‰æä¾›å•†å‡å¤±è´¥
        """
        for provider_type, provider_instance in self.providers.items():
            if provider_type not in exclude:
                try:
                    print(f"ğŸ”„ å°è¯•å¤‡ç”¨æä¾›å•†: {provider_type.value}")
                    return await provider_instance.generate(request)
                except ProviderError as e:
                    print(f"âš ï¸  æä¾›å•† {provider_type.value} å¤±è´¥: {e}")
                    continue

        raise ProviderError("æ‰€æœ‰æä¾›å•†å‡å¤±è´¥")

    def get_provider(self, provider_type: ProviderType) -> BaseLLMProvider:
        """
        è·å–æŒ‡å®šæä¾›å•†

        Args:
            provider_type: æä¾›å•†ç±»å‹

        Returns:
            æä¾›å•†å®ä¾‹

        Raises:
            ValueError: æä¾›å•†ä¸å¯ç”¨
        """
        if provider_type not in self.providers:
            raise ValueError(f"æä¾›å•† {provider_type} ä¸å¯ç”¨")
        return self.providers[provider_type]

    def get_available_providers(self) -> List[ProviderType]:
        """
        è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨

        Returns:
            æä¾›å•†ç±»å‹åˆ—è¡¨
        """
        return list(self.providers.keys())

    def health_check(self) -> Dict[ProviderType, bool]:
        """
        å¥åº·æ£€æŸ¥æ‰€æœ‰æä¾›å•†

        Returns:
            æä¾›å•†å¥åº·çŠ¶æ€å­—å…¸
        """
        results = {}
        for provider_type, provider in self.providers.items():
            results[provider_type] = provider.health_check()
        return results

    async def close_all(self):
        """å…³é—­æ‰€æœ‰æä¾›å•†çš„è¿æ¥"""
        for provider in self.providers.values():
            if hasattr(provider, "close"):
                await provider.close()

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close_all()


def load_llm_config(config_file: str = "config/llm.yaml") -> Dict[str, Any]:
    """
    åŠ è½½ LLM é…ç½®

    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        é…ç½®å­—å…¸
    """
    import os
    from pathlib import Path

    try:
        import yaml
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… pyyaml: pip install pyyaml")

    config_path = Path(config_file)

    if not config_path.exists():
        # è¿”å›é»˜è®¤é…ç½®
        return {"LLM": {"default_provider": "qwen"}}

    # è¯»å–é…ç½®
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # æ›¿æ¢ç¯å¢ƒå˜é‡
    def replace_env_vars(obj):
        """é€’å½’æ›¿æ¢ç¯å¢ƒå˜é‡"""
        if isinstance(obj, dict):
            return {k: replace_env_vars(v) for k, v in obj.items()}
        elif isinstance(obj, str):
            if obj.startswith("${") and obj.endswith("}"):
                env_var = obj[2:-1]
                return os.getenv(env_var, obj)
            return obj
        else:
            return obj

    config = replace_env_vars(config)

    return config
