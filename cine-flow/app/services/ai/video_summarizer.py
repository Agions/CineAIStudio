#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AI è§†é¢‘æ‘˜è¦ç”Ÿæˆå™¨ (Video Summarizer)

åŸºäºè§†é¢‘ç”»é¢åˆ†æç”Ÿæˆæ™ºèƒ½æ‘˜è¦ï¼Œæ”¯æŒå¤šç§æ‘˜è¦ç±»å‹å’Œé£æ ¼ã€‚

åŠŸèƒ½:
- ç”Ÿæˆè§†é¢‘å†…å®¹æ‘˜è¦
- æå–å…³é”®ä¿¡æ¯ç‚¹
- ç”Ÿæˆæ—¶é—´æˆ³æ ‡è®°
- æ”¯æŒå¤šç§æ‘˜è¦é£æ ¼ï¼ˆç®€æ´ã€è¯¦ç»†ã€æ•…äº‹åŒ–ï¼‰

ä½¿ç”¨ç¤ºä¾‹:
    from app.services.ai import VideoSummarizer, SummaryStyle

    summarizer = VideoSummarizer()
    summary = summarizer.summarize("video.mp4", style=SummaryStyle.DETAILED)

    print(f"æ ‡é¢˜: {summary.title}")
    print(f"æ‘˜è¦: {summary.content}")
    for point in summary.key_points:
        print(f"  [{point.timestamp}] {point.description}")
"""

import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum

from .video_content_analyzer import VideoContentAnalyzer, VideoAnalysisResult
from .llm_manager import LLMManager, load_llm_config, ProviderType
from .base_LLM_provider import LLMRequest


class SummaryStyle(Enum):
    """æ‘˜è¦é£æ ¼"""
    CONCISE = "concise"          # ç®€æ´ï¼ˆ100å­—ä»¥å†…ï¼‰
    DETAILED = "detailed"        # è¯¦ç»†ï¼ˆ300-500å­—ï¼‰
    STORY = "story"              # æ•…äº‹åŒ–
    BULLET = "bullet"            # è¦ç‚¹åˆ—è¡¨
    SOCIAL = "social"            # ç¤¾äº¤åª’ä½“é£æ ¼


class SummaryLength(Enum):
    """æ‘˜è¦é•¿åº¦"""
    SHORT = "short"              # çŸ­ï¼ˆ50-100å­—ï¼‰
    MEDIUM = "medium"            # ä¸­ï¼ˆ200-300å­—ï¼‰
    LONG = "long"                # é•¿ï¼ˆ400-600å­—ï¼‰


@dataclass
class KeyPoint:
    """å…³é”®ä¿¡æ¯ç‚¹"""
    timestamp: float             # æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
    description: str             # æè¿°
    importance: int = 5          # é‡è¦ç¨‹åº¦ (1-10)


@dataclass
class VideoSummary:
    """è§†é¢‘æ‘˜è¦ç»“æœ"""
    title: str                   # æ ‡é¢˜
    content: str                 # æ‘˜è¦å†…å®¹
    style: SummaryStyle          # é£æ ¼
    key_points: List[KeyPoint] = field(default_factory=list)  # å…³é”®ä¿¡æ¯ç‚¹
    tags: List[str] = field(default_factory=list)  # æ ‡ç­¾
    sentiment: str = "neutral"   # æƒ…æ„Ÿå€¾å‘
    duration: float = 0.0        # è§†é¢‘æ—¶é•¿
    word_count: int = 0          # å­—æ•°


@dataclass
class SummarizerConfig:
    """æ‘˜è¦ç”Ÿæˆé…ç½®"""
    style: SummaryStyle = SummaryStyle.DETAILED
    length: SummaryLength = SummaryLength.MEDIUM
    include_timestamps: bool = True  # æ˜¯å¦åŒ…å«æ—¶é—´æˆ³
    include_tags: bool = True        # æ˜¯å¦ç”Ÿæˆæ ‡ç­¾
    language: str = "zh-CN"          # è¯­è¨€
    provider: Optional[str] = None   # æŒ‡å®š LLM æä¾›å•†


class VideoSummarizer:
    """
    AI è§†é¢‘æ‘˜è¦ç”Ÿæˆå™¨

    ä½¿ç”¨ LLM åŸºäºè§†é¢‘ç”»é¢åˆ†æç”Ÿæˆæ™ºèƒ½æ‘˜è¦

    ä½¿ç”¨ç¤ºä¾‹:
        summarizer = VideoSummarizer()

        # ç”Ÿæˆè¯¦ç»†æ‘˜è¦
        summary = summarizer.summarize("video.mp4")

        # ç”Ÿæˆç¤¾äº¤åª’ä½“é£æ ¼æ‘˜è¦
        social_summary = summarizer.summarize(
            "video.mp4",
            config=SummarizerConfig(style=SummaryStyle.SOCIAL)
        )
    """

    # é£æ ¼å¯¹åº”çš„ç³»ç»Ÿæç¤ºè¯
    STYLE_PROMPTS = {
        SummaryStyle.CONCISE: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘æ‘˜è¦æ’°å†™è€…ã€‚è¯·ç”Ÿæˆç®€æ´çš„è§†é¢‘æ‘˜è¦ã€‚
è¦æ±‚ï¼š
- å­—æ•°æ§åˆ¶åœ¨100å­—ä»¥å†…
- çªå‡ºæ ¸å¿ƒå†…å®¹
- è¯­è¨€ç²¾ç‚¼æœ‰åŠ›
- é€‚åˆå¿«é€Ÿæµè§ˆ""",

        SummaryStyle.DETAILED: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘æ‘˜è¦æ’°å†™è€…ã€‚è¯·ç”Ÿæˆè¯¦ç»†çš„è§†é¢‘æ‘˜è¦ã€‚
è¦æ±‚ï¼š
- å­—æ•°300-500å­—
- æ¶µç›–ä¸»è¦å†…å®¹
- é€»è¾‘æ¸…æ™°
- é€‚åˆæ·±å…¥äº†è§£è§†é¢‘å†…å®¹""",

        SummaryStyle.STORY: """ä½ æ˜¯ä¸€ä½æ“…é•¿è®²æ•…äº‹çš„è§†é¢‘æ‘˜è¦æ’°å†™è€…ã€‚è¯·ä»¥æ•…äº‹åŒ–çš„æ–¹å¼æè¿°è§†é¢‘å†…å®¹ã€‚
è¦æ±‚ï¼š
- æœ‰èµ·æ‰¿è½¬åˆ
- å¼•äººå…¥èƒœ
- æƒ…æ„Ÿä¸°å¯Œ
- è®©è¯»è€…æœ‰èº«ä¸´å…¶å¢ƒçš„æ„Ÿè§‰""",

        SummaryStyle.BULLET: """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘æ‘˜è¦æ’°å†™è€…ã€‚è¯·ä»¥è¦ç‚¹åˆ—è¡¨çš„å½¢å¼æ€»ç»“è§†é¢‘å†…å®¹ã€‚
è¦æ±‚ï¼š
- ä½¿ç”¨ bullet points
- æ¯ä¸ªè¦ç‚¹ç®€æ´æ˜äº†
- æŒ‰é‡è¦æ€§æ’åº
- ä¾¿äºå¿«é€Ÿè·å–ä¿¡æ¯""",

        SummaryStyle.SOCIAL: """ä½ æ˜¯ä¸€ä½ç¤¾äº¤åª’ä½“æ–‡æ¡ˆé«˜æ‰‹ã€‚è¯·ç”Ÿæˆé€‚åˆç¤¾äº¤åª’ä½“åˆ†äº«çš„è§†é¢‘æ‘˜è¦ã€‚
è¦æ±‚ï¼š
- å¼€å¤´æŠ“äººçœ¼çƒ
- ä½¿ç”¨ emoji å¢åŠ è¶£å‘³æ€§
- é€‚åˆæŠ–éŸ³ã€å°çº¢ä¹¦ã€å¾®åšç­‰å¹³å°
- é¼“åŠ±äº’åŠ¨ï¼ˆç‚¹èµã€è¯„è®ºã€è½¬å‘ï¼‰""",
    }

    def __init__(
        self,
        use_llm_manager: bool = True,
        llm_config: Optional[Dict[str, Any]] = None,
        api_key: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆå™¨

        Args:
            use_llm_manager: æ˜¯å¦ä½¿ç”¨ LLMManager
            llm_config: LLM é…ç½®
            api_key: OpenAI API Keyï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
        """
        self.use_llm_manager = use_llm_manager
        self.llm_manager: Optional[LLMManager] = None
        self.video_analyzer = VideoContentAnalyzer()

        if use_llm_manager:
            config = llm_config or load_llm_config()
            self.llm_manager = LLMManager(config)
        elif api_key:
            self.api_key = api_key
        else:
            self.api_key = os.getenv("OPENAI_API_KEY")

    async def summarize(
        self,
        video_path: str,
        config: Optional[SummarizerConfig] = None,
    ) -> VideoSummary:
        """
        ç”Ÿæˆè§†é¢‘æ‘˜è¦

        Args:
            video_path: è§†é¢‘è·¯å¾„
            config: æ‘˜è¦é…ç½®

        Returns:
            è§†é¢‘æ‘˜è¦
        """
        config = config or SummarizerConfig()

        # 1. åˆ†æè§†é¢‘å†…å®¹
        print("æ­£åœ¨åˆ†æè§†é¢‘å†…å®¹...")
        analysis = self.video_analyzer.analyze(video_path)

        # 2. ç”Ÿæˆæ‘˜è¦
        print("æ­£åœ¨ç”Ÿæˆæ‘˜è¦...")
        if self.use_llm_manager and self.llm_manager:
            summary_data = await self._generate_with_llm_manager(analysis, config)
        else:
            summary_data = self._generate_with_openai(analysis, config)

        # 3. æ„å»ºç»“æœ
        summary = VideoSummary(
            title=summary_data.get("title", "è§†é¢‘æ‘˜è¦"),
            content=summary_data.get("content", ""),
            style=config.style,
            key_points=summary_data.get("key_points", []),
            tags=summary_data.get("tags", []),
            sentiment=summary_data.get("sentiment", "neutral"),
            duration=analysis.duration,
            word_count=len(summary_data.get("content", "")),
        )

        return summary

    async def _generate_with_llm_manager(
        self,
        analysis: VideoAnalysisResult,
        config: SummarizerConfig,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLMManager ç”Ÿæˆæ‘˜è¦"""
        # æ„å»ºæç¤ºè¯
        system_prompt = self.STYLE_PROMPTS.get(
            config.style,
            self.STYLE_PROMPTS[SummaryStyle.DETAILED]
        )

        user_prompt = self._build_summary_prompt(analysis, config)

        # ç¡®å®šæä¾›å•†
        provider_type = None
        if config.provider:
            try:
                provider_type = ProviderType(config.provider)
            except ValueError:
                pass

        # æ„å»ºè¯·æ±‚
        request = LLMRequest(
            prompt=user_prompt,
            system_prompt=system_prompt,
            max_tokens=2000,
            temperature=0.7,
        )

        # è°ƒç”¨ LLM
        response = await self.llm_manager.generate(request, provider=provider_type)

        # è§£æå“åº”
        return self._parse_summary_response(response.content)

    def _generate_with_openai(
        self,
        analysis: VideoAnalysisResult,
        config: SummarizerConfig,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ OpenAI ç”Ÿæˆæ‘˜è¦"""
        try:
            from openai import OpenAI

            client = OpenAI(api_key=self.api_key)

            system_prompt = self.STYLE_PROMPTS.get(
                config.style,
                self.STYLE_PROMPTS[SummaryStyle.DETAILED]
            )

            user_prompt = self._build_summary_prompt(analysis, config)

            response = client.chat.completions.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=2000,
                temperature=0.7,
            )

            content = response.choices[0].message.content
            return self._parse_summary_response(content)

        except Exception as e:
            print(f"OpenAI ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_summary(analysis)

    def _build_summary_prompt(
        self,
        analysis: VideoAnalysisResult,
        config: SummarizerConfig,
    ) -> str:
        """æ„å»ºæ‘˜è¦ç”Ÿæˆæç¤ºè¯"""
        # æ”¶é›†å…³é”®å¸§æè¿°
        frame_descriptions = []
        for kf in analysis.keyframes[:10]:  # æœ€å¤šå–10å¸§
            if kf.description:
                frame_descriptions.append(f"[{kf.timestamp:.1f}s] {kf.description}")

        # é•¿åº¦è¦æ±‚
        length_map = {
            SummaryLength.SHORT: "50-100å­—",
            SummaryLength.MEDIUM: "200-300å­—",
            SummaryLength.LONG: "400-600å­—",
        }
        length_req = length_map.get(config.length, "200-300å­—")

        prompt_parts = [
            f"è¯·ä¸ºä»¥ä¸‹è§†é¢‘ç”Ÿæˆæ‘˜è¦ï¼š",
            f"",
            f"è§†é¢‘ä¿¡æ¯ï¼š",
            f"- æ—¶é•¿: {analysis.duration:.1f}ç§’",
            f"- åˆ†è¾¨ç‡: {analysis.resolution[0]}x{analysis.resolution[1]}",
            f"- ä¸»è¦ä¸»é¢˜: {', '.join(analysis.main_topics) if analysis.main_topics else 'æœªè¯†åˆ«'}",
            f"- æƒ…æ„ŸåŸºè°ƒ: {analysis.main_emotion.value}",
            f"",
            f"ç”»é¢æè¿°ï¼š",
        ]

        for desc in frame_descriptions:
            prompt_parts.append(f"  {desc}")

        prompt_parts.extend([
            f"",
            f"è¦æ±‚ï¼š",
            f"- å­—æ•°è¦æ±‚: {length_req}",
        ])

        if config.include_timestamps:
            prompt_parts.append("- åŒ…å«3-5ä¸ªå…³é”®æ—¶é—´ç‚¹åŠå…¶æè¿°")

        if config.include_tags:
            prompt_parts.append("- ç”Ÿæˆ5-8ä¸ªç›¸å…³æ ‡ç­¾")

        prompt_parts.extend([
            f"",
            f"è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š",
            f"```json",
            f"{{",
            f'  "title": "è§†é¢‘æ ‡é¢˜",',
            f'  "content": "æ‘˜è¦å†…å®¹",',
            f'  "key_points": [',
            f'    {{"timestamp": 10.5, "description": "å…³é”®æ—¶åˆ»æè¿°", "importance": 8}}',
            f'  ],',
            f'  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],',
            f'  "sentiment": "positive/neutral/negative"',
            f"}}",
            f"```",
        ])

        return "\n".join(prompt_parts)

    def _parse_summary_response(self, content: str) -> Dict[str, Any]:
        """è§£æ LLM å“åº”"""
        import json
        import re

        # å°è¯•æå– JSON
        try:
            # æŸ¥æ‰¾ JSON ä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£æ
                json_str = content

            data = json.loads(json_str)

            # è½¬æ¢å…³é”®ä¿¡æ¯ç‚¹
            key_points = []
            for point in data.get("key_points", []):
                key_points.append(KeyPoint(
                    timestamp=point.get("timestamp", 0),
                    description=point.get("description", ""),
                    importance=point.get("importance", 5),
                ))

            return {
                "title": data.get("title", "è§†é¢‘æ‘˜è¦"),
                "content": data.get("content", ""),
                "key_points": key_points,
                "tags": data.get("tags", []),
                "sentiment": data.get("sentiment", "neutral"),
            }

        except json.JSONDecodeError as e:
            print(f"JSON è§£æå¤±è´¥: {e}")
            # è¿”å›ç®€åŒ–ç‰ˆæœ¬
            return {
                "title": "è§†é¢‘æ‘˜è¦",
                "content": content[:500],
                "key_points": [],
                "tags": [],
                "sentiment": "neutral",
            }

    def _generate_fallback_summary(
        self,
        analysis: VideoAnalysisResult,
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå¤‡ç”¨æ‘˜è¦ï¼ˆå½“ LLM å¤±è´¥æ—¶ï¼‰"""
        # åŸºäºåˆ†æç»“æœç”Ÿæˆç®€å•æ‘˜è¦
        descriptions = [kf.description for kf in analysis.keyframes if kf.description]
        content = " ".join(descriptions[:5]) if descriptions else "è§†é¢‘å†…å®¹åˆ†æå®Œæˆ"

        return {
            "title": f"{analysis.duration:.0f}ç§’è§†é¢‘æ‘˜è¦",
            "content": content,
            "key_points": [
                KeyPoint(
                    timestamp=kf.timestamp,
                    description=kf.description[:50] if kf.description else f"åœºæ™¯ {i+1}",
                    importance=5,
                )
                for i, kf in enumerate(analysis.keyframes[:5])
            ],
            "tags": analysis.main_topics,
            "sentiment": analysis.main_emotion.value,
        }

    def generate_title(
        self,
        video_path: str,
        style: str = "catchy",  # catchy, descriptive, seo
    ) -> str:
        """
        ç”Ÿæˆè§†é¢‘æ ‡é¢˜

        Args:
            video_path: è§†é¢‘è·¯å¾„
            style: æ ‡é¢˜é£æ ¼ (catchy=æŠ“çœ¼çƒ, descriptive=æè¿°æ€§, seo=SEOä¼˜åŒ–)

        Returns:
            æ ‡é¢˜
        """
        # ç®€åŒ–å®ç°ï¼šå…ˆåˆ†æå†ç”Ÿæˆ
        analysis = self.video_analyzer.analyze(video_path)

        # åŸºäºåˆ†æç»“æœç”Ÿæˆæ ‡é¢˜
        if style == "catchy":
            return f"éœ‡æƒŠï¼{analysis.main_topics[0] if analysis.main_topics else 'è¿™ä¸ªè§†é¢‘'}ç«Ÿç„¶..."
        elif style == "descriptive":
            return f"{analysis.duration:.0f}ç§’å¸¦ä½ äº†è§£{', '.join(analysis.main_topics[:2])}"
        else:
            return f"{', '.join(analysis.keywords[:5])} | è§†é¢‘è§£æ"

    def generate_chapters(
        self,
        video_path: str,
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆè§†é¢‘ç« èŠ‚

        Args:
            video_path: è§†é¢‘è·¯å¾„

        Returns:
            ç« èŠ‚åˆ—è¡¨
        """
        analysis = self.video_analyzer.analyze(video_path)

        chapters = []
        for i, kf in enumerate(analysis.keyframes):
            if kf.description:
                chapters.append({
                    "timestamp": kf.timestamp,
                    "title": f"ç« èŠ‚ {i+1}",
                    "description": kf.description[:50],
                })

        return chapters


# =========== ä¾¿æ·å‡½æ•° ===========

async def summarize_video(
    video_path: str,
    style: SummaryStyle = SummaryStyle.DETAILED,
    use_llm_manager: bool = True,
) -> VideoSummary:
    """
    å¿«é€Ÿç”Ÿæˆè§†é¢‘æ‘˜è¦

    Args:
        video_path: è§†é¢‘è·¯å¾„
        style: æ‘˜è¦é£æ ¼
        use_llm_manager: æ˜¯å¦ä½¿ç”¨ LLMManager

    Returns:
        è§†é¢‘æ‘˜è¦
    """
    summarizer = VideoSummarizer(use_llm_manager=use_llm_manager)
    config = SummarizerConfig(style=style)
    return await summarizer.summarize(video_path, config)


def demo_summarize():
    """æ¼”ç¤ºè§†é¢‘æ‘˜è¦ç”Ÿæˆ"""
    print("=" * 60)
    print("ğŸ¬ AI è§†é¢‘æ‘˜è¦ç”Ÿæˆå™¨")
    print("=" * 60)

    # æ£€æŸ¥æµ‹è¯•è§†é¢‘
    test_videos = list(Path("test_assets").glob("*.mp4"))

    if not test_videos:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•è§†é¢‘")
        print("è¯·å°† .mp4 æ–‡ä»¶æ”¾å…¥ test_assets ç›®å½•")
        return

    video_path = str(test_videos[0])
    print(f"\nåˆ†æè§†é¢‘: {video_path}")

    import asyncio

    async def run():
        summarizer = VideoSummarizer(use_llm_manager=True)

        # ç”Ÿæˆä¸åŒé£æ ¼çš„æ‘˜è¦
        for style in [SummaryStyle.CONCISE, SummaryStyle.DETAILED]:
            print(f"\n{'='*60}")
            print(f"é£æ ¼: {style.value}")
            print("=" * 60)

            config = SummarizerConfig(style=style)
            summary = await summarizer.summarize(video_path, config)

            print(f"\nğŸ“Œ æ ‡é¢˜: {summary.title}")
            print(f"ğŸ“ æ‘˜è¦: {summary.content[:200]}...")
            print(f"ğŸ·ï¸  æ ‡ç­¾: {', '.join(summary.tags[:5])}")
            print(f"ğŸ’­ æƒ…æ„Ÿ: {summary.sentiment}")

            if summary.key_points:
                print(f"\nâ±ï¸  å…³é”®æ—¶é—´ç‚¹:")
                for point in summary.key_points[:3]:
                    print(f"   [{point.timestamp:.1f}s] {point.description[:50]}...")

    asyncio.run(run())


if __name__ == '__main__':
    demo_summarize()
